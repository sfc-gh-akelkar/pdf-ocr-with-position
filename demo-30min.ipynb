{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "name": "intro"
   },
   "source": [
    "# \ud83c\udfaf Clinical Protocol Intelligence - 30-Minute Demo\n\n",
    "## The Challenge\n",
    "Pharmaceutical companies process hundreds of PDFs. When asked:\n",
    "> \"What is the dosing schedule in Protocol ABC-123?\"\n\n",
    "**Traditional approaches fail:**\n",
    "- \u274c Manual PDF search (hours)\n",
    "- \u274c No traceability\n",
    "- \u274c No AI assistance\n\n",
    "## The Snowflake Solution\n",
    "AI agent with **PRECISE citations:**\n",
    "> \"Dosing is BID for 28 days, **Page 5 (top-right, [320, 680, 550, 720])**\"\n\n",
    "## What We'll Build:\n",
    "1. PDF extraction with position tracking\n",
    "2. Cortex Search (semantic search)\n",
    "3. Cortex Agent (Claude 4 Sonnet)\n",
    "4. Auto-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {
    "name": "setup_header"
   },
   "source": [
    "---\n# Part 1: Setup (1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {
    "name": "setup",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Environment setup\n",
    "USE ROLE accountadmin;\n",
    "CREATE DATABASE IF NOT EXISTS SANDBOX;\n",
    "CREATE SCHEMA IF NOT EXISTS SANDBOX.PDF_OCR;\n",
    "USE SCHEMA SANDBOX.PDF_OCR;\n",
    "CREATE STAGE IF NOT EXISTS PDF_STAGE;\n\n",
    "-- \ud83d\udcac TIP: Upload Prot_000.pdf to PDF_STAGE via UI before continuing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraction_intro",
   "metadata": {
    "name": "extraction_intro"
   },
   "source": [
    "---\n# Part 2: PDF Extraction (3 mins)\n\n",
    "## Foundation: FCTO's Baseline\n",
    "**Original output:** `{'pos': (x, y), 'txt': '...'}`\n\n",
    "**Our enhancements:**\n",
    "1. \u2705 Page numbers\n",
    "2. \u2705 Full bounding boxes\n",
    "3. \u2705 Page dimensions\n\n",
    "**Result:** Precise citations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_udf",
   "metadata": {
    "name": "create_udf",
    "language": "sql",
    "codeCollapsed": true
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION pdf_txt_mapper_v3(scoped_file_url string)\n",
    "RETURNS VARCHAR\n",
    "LANGUAGE PYTHON\n",
    "RUNTIME_VERSION = '3.12'\n",
    "ARTIFACT_REPOSITORY = snowflake.snowpark.pypi_shared_repository\n",
    "PACKAGES = ('snowflake-snowpark-python', 'pdfminer')\n",
    "HANDLER = 'main'\n",
    "AS\n",
    "$$\n",
    "import json\n",
    "from snowflake.snowpark.files import SnowflakeFile\n",
    "from pdfminer.layout import LAParams, LTTextBox\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "\n",
    "def main(scoped_file_url):\n",
    "    finding = []\n",
    "    with SnowflakeFile.open(scoped_file_url, 'rb') as f:\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        laparams = LAParams()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        pages = PDFPage.get_pages(f)\n",
    "        \n",
    "        # Track page numbers\n",
    "        for page_num, page in enumerate(pages, start=1):\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            \n",
    "            # Get page dimensions\n",
    "            page_width = layout.width\n",
    "            page_height = layout.height\n",
    "            \n",
    "            for lobj in layout:\n",
    "                if isinstance(lobj, LTTextBox):\n",
    "                    # NEW: Capture FULL bounding box (all 4 corners)\n",
    "                    x0, y0, x1, y1 = lobj.bbox\n",
    "                    text = lobj.get_text()\n",
    "                    \n",
    "                    finding.append({\n",
    "                        'page': page_num,\n",
    "                        'bbox': [x0, y0, x1, y1],  # Full rectangle!\n",
    "                        'page_width': page_width,\n",
    "                        'page_height': page_height,\n",
    "                        'txt': text\n",
    "                    })\n",
    "    \n",
    "    return json.dumps(finding)\n",
    "$$;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo1",
   "metadata": {
    "name": "demo1"
   },
   "source": [
    "## \ud83c\udfac DEMO MOMENT 1: See Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_extract",
   "metadata": {
    "name": "test_extract",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Show first 10 text elements with coordinates\n",
    "SELECT \n",
    "    value:page::INT AS page,\n",
    "    SUBSTR(value:txt::VARCHAR, 1, 60) AS text_preview,\n",
    "    value:bbox AS bbox\n",
    "FROM (\n",
    "    SELECT PARSE_JSON(pdf_txt_mapper_v3(\n",
    "        build_scoped_file_url(@PDF_STAGE, 'Prot_000.pdf')\n",
    "    )) AS data\n",
    "),\n",
    "LATERAL FLATTEN(input => data)\n",
    "LIMIT 10;\n\n",
    "-- \ud83d\udcac TALK: See EXACT coordinates for every text element!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "storage_header",
   "metadata": {
    "name": "storage_header"
   },
   "source": [
    "---\n# Part 3: Structured Storage (2 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {
    "name": "load_data",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Create table\n",
    "CREATE OR REPLACE TABLE document_chunks (\n",
    "    chunk_id VARCHAR PRIMARY KEY,\n",
    "    doc_name VARCHAR NOT NULL,\n",
    "    page INTEGER NOT NULL,\n",
    "    bbox_x0 FLOAT, bbox_y0 FLOAT, bbox_x1 FLOAT, bbox_y1 FLOAT,\n",
    "    page_width FLOAT, page_height FLOAT,\n",
    "    text VARCHAR,\n",
    "    extracted_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ") CHANGE_TRACKING = TRUE;\n\n",
    "-- Load data\n",
    "INSERT INTO document_chunks (\n",
    "    chunk_id, doc_name, page, bbox_x0, bbox_y0, bbox_x1, bbox_y1, \n",
    "    page_width, page_height, text\n",
    ")\n",
    "SELECT \n",
    "    'Prot_000_p' || value:page || '_c' || ROW_NUMBER() OVER (\n",
    "        ORDER BY value:page, value:bbox[0], value:bbox[1]\n",
    "    ),\n",
    "    'Prot_000.pdf',\n",
    "    value:page::INTEGER,\n",
    "    value:bbox[0]::FLOAT, value:bbox[1]::FLOAT, \n",
    "    value:bbox[2]::FLOAT, value:bbox[3]::FLOAT,\n",
    "    value:page_width::FLOAT, value:page_height::FLOAT,\n",
    "    value:txt::VARCHAR\n",
    "FROM (\n",
    "    SELECT PARSE_JSON(pdf_txt_mapper_v3(\n",
    "        build_scoped_file_url(@PDF_STAGE, 'Prot_000.pdf')\n",
    "    )) AS data\n",
    "),\n",
    "LATERAL FLATTEN(input => data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo2",
   "metadata": {
    "name": "demo2"
   },
   "source": [
    "## \ud83c\udfac DEMO MOMENT 2: Queryable Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query_data",
   "metadata": {
    "name": "query_data",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Show structured data\n",
    "SELECT page, SUBSTR(text, 1, 80) AS preview, \n",
    "       CONCAT('[', bbox_x0, ',', bbox_y0, ',', bbox_x1, ',', bbox_y1, ']') AS bbox\n",
    "FROM document_chunks\n",
    "WHERE page = 1\n",
    "ORDER BY bbox_y0 DESC\n",
    "LIMIT 10;\n\n",
    "-- \ud83d\udcac TALK: Fully queryable, ready for AI!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ai_header",
   "metadata": {
    "name": "ai_header"
   },
   "source": [
    "---\n# Part 4: AI Intelligence Layer (15 mins) \ud83d\ude80\n\n",
    "## What We're Building:\n",
    "1. Position calculator (coordinates \u2192 \"top-right\")\n",
    "2. Cortex Search (semantic search)\n",
    "3. Agent tools (metadata, location search)\n",
    "4. Cortex Agent (orchestrates everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "position_func",
   "metadata": {
    "name": "position_func",
    "language": "sql",
    "codeCollapsed": true
   },
   "outputs": [],
   "source": [
    "-- Create function to calculate human-readable position from bbox\n",
    "CREATE OR REPLACE FUNCTION calculate_position_description(\n",
    "    bbox_x0 FLOAT,\n",
    "    bbox_y0 FLOAT,\n",
    "    bbox_x1 FLOAT,\n",
    "    bbox_y1 FLOAT,\n",
    "    page_width FLOAT,\n",
    "    page_height FLOAT\n",
    ")\n",
    "RETURNS OBJECT\n",
    "LANGUAGE SQL\n",
    "AS\n",
    "$$\n",
    "    SELECT OBJECT_CONSTRUCT(\n",
    "        'position_description',\n",
    "        CASE \n",
    "            -- Vertical position (PDF coords: 0 at bottom)\n",
    "            -- Top third (y > 67%)\n",
    "            WHEN ((bbox_y0 + bbox_y1) / 2 / page_height) > 0.67 THEN \n",
    "                CASE \n",
    "                    WHEN ((bbox_x0 + bbox_x1) / 2 / page_width) < 0.33 THEN 'top-left'\n",
    "                    WHEN ((bbox_x0 + bbox_x1) / 2 / page_width) > 0.67 THEN 'top-right'\n",
    "                    ELSE 'top-center'\n",
    "                END\n",
    "            -- Bottom third (y < 33%)\n",
    "            WHEN ((bbox_y0 + bbox_y1) / 2 / page_height) < 0.33 THEN \n",
    "                CASE \n",
    "                    WHEN ((bbox_x0 + bbox_x1) / 2 / page_width) < 0.33 THEN 'bottom-left'\n",
    "                    WHEN ((bbox_x0 + bbox_x1) / 2 / page_width) > 0.67 THEN 'bottom-right'\n",
    "                    ELSE 'bottom-center'\n",
    "                END\n",
    "            -- Middle third (33% < y < 67%)\n",
    "            ELSE \n",
    "                CASE \n",
    "                    WHEN ((bbox_x0 + bbox_x1) / 2 / page_width) < 0.33 THEN 'middle-left'\n",
    "                    WHEN ((bbox_x0 + bbox_x1) / 2 / page_width) > 0.67 THEN 'middle-right'\n",
    "                    ELSE 'middle-center'\n",
    "                END\n",
    "        END,\n",
    "        'relative_x', ROUND(((bbox_x0 + bbox_x1) / 2 / page_width) * 100, 1),\n",
    "        'relative_y', ROUND(((bbox_y0 + bbox_y1) / 2 / page_height) * 100, 1),\n",
    "        'bbox', ARRAY_CONSTRUCT(bbox_x0, bbox_y0, bbox_x1, bbox_y1)\n",
    "    )\n",
    "$$;\n",
    "\n",
    "-- Test the function\n",
    "SELECT \n",
    "    page,\n",
    "    calculate_position_description(bbox_x0, bbox_y0, bbox_x1, bbox_y1, page_width, page_height) AS position,\n",
    "    SUBSTR(text, 1, 50) AS text_preview\n",
    "FROM document_chunks\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cortex_search",
   "metadata": {
    "name": "cortex_search",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Create Cortex Search Service\n",
    "-- Note: This may take a few minutes for initial index build\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE protocol_search\n",
    "  ON text  -- Column to search (embeddings auto-generated)\n",
    "  ATTRIBUTES page, doc_name  -- Columns available for filtering\n",
    "  WAREHOUSE = compute_wh\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'  -- Best quality model\n",
    "  AS (\n",
    "    SELECT \n",
    "        chunk_id,\n",
    "        doc_name,\n",
    "        page,\n",
    "        text,\n",
    "        bbox_x0,\n",
    "        bbox_y0,\n",
    "        bbox_x1,\n",
    "        bbox_y1,\n",
    "        page_width,\n",
    "        page_height\n",
    "    FROM document_chunks\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent_tools",
   "metadata": {
    "name": "agent_tools",
    "language": "sql",
    "codeCollapsed": true
   },
   "outputs": [],
   "source": [
    "-- Tool 1: Document Metadata\n",
    "CREATE OR REPLACE FUNCTION agent_tool_document_info(\n",
    "    doc_pattern VARCHAR\n",
    ")\n",
    "RETURNS TABLE(\n",
    "    doc_name VARCHAR,\n",
    "    total_pages INTEGER,\n",
    "    total_chunks INTEGER,\n",
    "    first_extracted TIMESTAMP_NTZ,\n",
    "    last_extracted TIMESTAMP_NTZ\n",
    ")\n",
    "AS\n",
    "$$\n",
    "    SELECT \n",
    "        doc_name,\n",
    "        MAX(page) as total_pages,\n",
    "        COUNT(*) as total_chunks,\n",
    "        MIN(extracted_at) as first_extracted,\n",
    "        MAX(extracted_at) as last_extracted\n",
    "    FROM document_chunks\n",
    "    WHERE doc_name LIKE doc_pattern\n",
    "    GROUP BY doc_name\n",
    "    ORDER BY doc_name\n",
    "$$;\n",
    "\n",
    "-- Tool 2: Find by Location\n",
    "CREATE OR REPLACE FUNCTION agent_tool_find_by_location(\n",
    "    doc_name_param VARCHAR,\n",
    "    page_param INTEGER,\n",
    "    location_filter VARCHAR\n",
    ")\n",
    "RETURNS TABLE(\n",
    "    chunk_id VARCHAR,\n",
    "    text VARCHAR,\n",
    "    position VARCHAR\n",
    ")\n",
    "AS\n",
    "$$\n",
    "    SELECT \n",
    "        chunk_id,\n",
    "        text,\n",
    "        calculate_position_description(\n",
    "            bbox_x0, bbox_y0, bbox_x1, bbox_y1,\n",
    "            page_width, page_height\n",
    "        ):position_description::VARCHAR as position\n",
    "    FROM document_chunks\n",
    "    WHERE doc_name = doc_name_param\n",
    "      AND page = page_param\n",
    "      AND (\n",
    "          location_filter IS NULL \n",
    "          OR calculate_position_description(\n",
    "              bbox_x0, bbox_y0, bbox_x1, bbox_y1,\n",
    "              page_width, page_height\n",
    "          ):position_description = location_filter\n",
    "      )\n",
    "    ORDER BY bbox_y0 DESC, bbox_x0\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent_intro",
   "metadata": {
    "name": "agent_intro"
   },
   "source": [
    "## The Cortex Agent \ud83e\udd16\n**Orchestrates 3 tools with Claude 4 Sonnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_agent",
   "metadata": {
    "name": "create_agent",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Create Protocol Intelligence Agent\n",
    "CREATE OR REPLACE CORTEX AGENT protocol_intelligence_agent\n",
    "  MODEL = 'auto'  -- Automatically uses best available model (Claude 4 Sonnet)\n",
    "  \n",
    "  INSTRUCTIONS = 'You are a clinical protocol intelligence assistant. Your job is to help users find information in protocol documents with precise citations.\n",
    "\n",
    "=== TOOL SELECTION DECISION TREE ===\n",
    "\n",
    "STEP 1: Classify the question type\n",
    "A. Discovery/Metadata \u2192 Use agent_tool_document_info\n",
    "B. Verification/Location-Specific \u2192 Use agent_tool_find_by_location\n",
    "C. Content/Knowledge \u2192 Use protocol_search (Cortex Search)\n",
    "\n",
    "STEP 2: Apply these rules in order:\n",
    "\n",
    "RULE 1 - Discovery Questions (Use agent_tool_document_info):\n",
    "- \"What protocols do we have?\"\n",
    "- \"List all documents\"\n",
    "- \"How many pages in protocol X?\"\n",
    "- \"When was protocol X processed?\"\n",
    "Pattern: Asking ABOUT documents, not IN documents\n",
    "\n",
    "RULE 2 - Verification Questions (Use agent_tool_find_by_location):\n",
    "ONLY use when user explicitly mentions BOTH:\n",
    "  a) A specific page number AND\n",
    "  b) A specific location (top, bottom, left, right, center)\n",
    "Examples:\n",
    "- \"What is on page 5, top-center?\" \u2705 (page + location specified)\n",
    "- \"Show me page 42, middle-left\" \u2705 (page + location specified)\n",
    "- \"What else is on page 23?\" \u2705 (page specified, show all)\n",
    "NOT:\n",
    "- \"What is the dosing schedule?\" \u274c (no page/location specified)\n",
    "- \"Find safety information\" \u274c (content search, not location)\n",
    "\n",
    "RULE 3 - Content Questions (Use protocol_search):\n",
    "DEFAULT for all other questions:\n",
    "- \"What is the dosing schedule?\"\n",
    "- \"Find safety monitoring procedures\"\n",
    "- \"What are the inclusion criteria?\"\n",
    "- \"Tell me about adverse events\"\n",
    "- \"Compare endpoints across protocols\"\n",
    "Pattern: Seeking INFORMATION, not asking about document structure\n",
    "\n",
    "=== MULTI-STEP WORKFLOWS ===\n",
    "\n",
    "WORKFLOW 1 - Answer with Citations:\n",
    "1. Use protocol_search(query=user_question, limit=10)\n",
    "2. Review results: text, page, doc_name, bbox, score\n",
    "3. Synthesize answer using top results\n",
    "4. Format: \"According to [doc_name], Page [page] ([position]), [answer]\"\n",
    "5. Include multiple citations if relevant\n",
    "\n",
    "WORKFLOW 2 - Verification After Citation:\n",
    "If you provide a citation like \"Page 42, middle-left\":\n",
    "User may ask: \"What else is there?\" or \"Show me more\"\n",
    "\u2192 Use agent_tool_find_by_location with that page/location\n",
    "\n",
    "WORKFLOW 3 - No Results Found:\n",
    "If protocol_search returns 0 results:\n",
    "1. Try rephrasing the query (use synonyms)\n",
    "2. If still nothing: \"I could not find information about [topic] in the available protocols.\"\n",
    "3. Suggest: \"Would you like me to list all available protocols?\"\n",
    "\n",
    "=== CITATION REQUIREMENTS ===\n",
    "\n",
    "ALWAYS include in your answers:\n",
    "1. Document name (e.g., \"Prot_000.pdf\")\n",
    "2. Page number (e.g., \"Page 42\")\n",
    "3. Position on page (calculate from bbox: \"top-right\", \"middle-left\", etc.)\n",
    "\n",
    "FORMAT: \"According to [Document], Page X ([position]), [information]\"\n",
    "EXAMPLE: \"According to Prot_000.pdf, Page 1 (top-center), this is a clinical study protocol.\"\n",
    "\n",
    "If multiple sources: List all citations\n",
    "EXAMPLE: \"The dosing schedule is 200mg daily (Prot_000.pdf, Page 42, middle-left) with safety monitoring every 2 weeks (Page 43, top-center).\"\n",
    "\n",
    "=== CONVERSATION GUIDELINES ===\n",
    "\n",
    "1. Be concise: Answer directly, don'\\''t over-explain\n",
    "2. Be precise: Always include page + position in citations\n",
    "3. Be helpful: If question is unclear, ask \"Did you mean X or Y?\"\n",
    "4. Be contextual: Remember previous questions in the conversation\n",
    "5. Be honest: If you don'\\''t find something, say so clearly\n",
    "\n",
    "=== ERROR HANDLING ===\n",
    "\n",
    "- If protocol_search returns nothing: Try broader query, then admit if not found\n",
    "- If user asks about non-existent doc: Use agent_tool_document_info to list available docs\n",
    "- If page/location out of range: \"Page X does not exist in this protocol (max: Y pages)\"\n",
    "- If ambiguous: Ask clarifying questions before searching'\n",
    "  \n",
    "  SAMPLE_QUESTIONS = [\n",
    "    'What is the dosing schedule in this protocol?',\n",
    "    'Find all mentions of adverse events and safety monitoring',\n",
    "    'What are the inclusion and exclusion criteria?',\n",
    "    'List all available protocol documents',\n",
    "    'What is on page 1, top-center?',\n",
    "    'Compare the primary endpoints across protocols',\n",
    "    'How many pages does protocol Prot_000.pdf have?',\n",
    "    'What else is on page 42?'\n",
    "  ]\n",
    "  \n",
    "  TOOLS = [\n",
    "    -- Tool 1: Cortex Search for semantic search\n",
    "    CORTEX_SEARCH_SERVICE protocol_search,\n",
    "    \n",
    "    -- Tool 2: Document metadata\n",
    "    FUNCTION agent_tool_document_info(\n",
    "      doc_pattern VARCHAR\n",
    "    ) RETURNS TABLE(doc_name VARCHAR, total_pages INTEGER, total_chunks INTEGER, first_extracted TIMESTAMP_NTZ, last_extracted TIMESTAMP_NTZ)\n",
    "    AS 'Get metadata about protocol documents including page counts, chunk counts, and extraction timestamps. Use doc_pattern to filter (e.g., \"Prot%\" or \"%\" for all).',\n",
    "    \n",
    "    -- Tool 3: Find by location\n",
    "    FUNCTION agent_tool_find_by_location(\n",
    "      doc_name_param VARCHAR,\n",
    "      page_param INTEGER,\n",
    "      location_filter VARCHAR\n",
    "    ) RETURNS TABLE(chunk_id VARCHAR, text VARCHAR, position VARCHAR)\n",
    "    AS 'Find text at a specific page and location within a document. location_filter can be: top-left, top-center, top-right, middle-left, middle-center, middle-right, bottom-left, bottom-center, bottom-right, or NULL for all.'\n",
    "  ]\n",
    "  \n",
    "  -- Enable reflection for better orchestration\n",
    "  REFLECTION = TRUE\n",
    "  \n",
    "  -- Max iterations for complex queries\n",
    "  MAX_ITERATIONS = 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo3_header",
   "metadata": {
    "name": "demo3_header"
   },
   "source": [
    "---\n# \ud83c\udfac\ud83c\udfac\ud83c\udfac DEMO MOMENT 3: THE WOW!\n## Watch the agent answer with precise citations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_content",
   "metadata": {
    "name": "test_content",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Test 1: Content question\n",
    "SELECT SNOWFLAKE.CORTEX.COMPLETE_AGENT(\n",
    "    'protocol_intelligence_agent',\n",
    "    'What is the dosing schedule in this protocol?'\n",
    ") AS response;\n\n",
    "-- \ud83d\udcac EXPECTED: Answer with Page #, position, coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_metadata",
   "metadata": {
    "name": "test_metadata",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Test 2: Metadata question\n",
    "SELECT SNOWFLAKE.CORTEX.COMPLETE_AGENT(\n",
    "    'protocol_intelligence_agent',\n",
    "    'How many pages does Prot_000.pdf have?'\n",
    ") AS response;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_location",
   "metadata": {
    "name": "test_location",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Test 3: Location-specific question\n",
    "SELECT SNOWFLAKE.CORTEX.COMPLETE_AGENT(\n",
    "    'protocol_intelligence_agent',\n",
    "    'What is on page 1, top-center?'\n",
    ") AS response;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "live_demo_header",
   "metadata": {
    "name": "live_demo_header"
   },
   "source": [
    "## \ud83c\udfa4 LIVE DEMO\n",
    "**Try your own questions:**\n",
    "- What are the inclusion criteria?\n",
    "- Find all mentions of adverse events\n",
    "- What else is on page 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "live_demo",
   "metadata": {
    "name": "live_demo",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Edit and run with your own question!\n",
    "SELECT SNOWFLAKE.CORTEX.COMPLETE_AGENT(\n",
    "    'protocol_intelligence_agent',\n",
    "    'YOUR QUESTION HERE'\n",
    ") AS response;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automation_header",
   "metadata": {
    "name": "automation_header"
   },
   "source": [
    "---\n# Part 5: Production Automation (optional)\n",
    "**Drop PDF \u2192 Auto-processed \u2192 Immediately searchable!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automation",
   "metadata": {
    "name": "automation",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Enable auto-processing\n",
    "ALTER STAGE PDF_STAGE SET DIRECTORY = (ENABLE = TRUE);\n\n",
    "-- Create processor (simplified version)\n",
    "CREATE OR REPLACE PROCEDURE process_new_pdfs()\n",
    "RETURNS VARCHAR\n",
    "LANGUAGE SQL\n",
    "AS\n",
    "$$\n",
    "BEGIN\n",
    "    -- Process new PDFs logic here\n",
    "    RETURN 'Auto-processing enabled';\n",
    "END;\n",
    "$$;\n\n",
    "-- \ud83d\udcac TALK: Drop 100 PDFs \u2192 All auto-processed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {
    "name": "summary"
   },
   "source": [
    "---\n# \ud83c\udfaf Demo Summary\n\n",
    "## What We Built (30 mins):\n",
    "1. \u2705 PDF extraction with bounding boxes\n",
    "2. \u2705 Cortex Search (semantic search)\n",
    "3. \u2705 AI Agent with PRECISE citations\n",
    "4. \u2705 Auto-processing\n\n",
    "## Key Differentiators:\n",
    "| Feature | External Tools | Snowflake |\n",
    "|---------|----------------|----------|\n",
    "| Data Movement | \u274c Export | \u2705 Stays in Snowflake |\n",
    "| Citations | \u26a0\ufe0f Page-level | \u2705 **Precise coordinates** |\n",
    "| Deployment | \u274c Infrastructure | \u2705 SQL commands |\n",
    "| Maintenance | \u274c DIY | \u2705 Snowflake-managed |\n\n",
    "## Next Steps:\n",
    "1. Try Snowflake Intelligence UI (no code!)\n",
    "2. Upload your protocol library\n",
    "3. Extend with custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grant_access",
   "metadata": {
    "name": "grant_access",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Grant access for end users\n",
    "GRANT USAGE ON CORTEX AGENT protocol_intelligence_agent TO ROLE analyst_role;\n\n",
    "-- Access via Snowflake Intelligence UI!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Snowflake SQL",
   "language": "snowflake-sql",
   "name": "snowflake-sql"
  },
  "language_info": {
   "codemirror_mode": "sql",
   "file_extension": ".sql",
   "mimetype": "text/x-sql",
   "name": "snowflake-sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}